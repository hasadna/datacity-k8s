apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: cco-update-instance
spec:
  entrypoint: cco-update-instance
  arguments:
    parameters:
      - name: INSTANCE_NAME
      - name: S3_FILESTORE_AWS_BUCKET_NAME
      - name: S3_FILESTORE_AWS_ACCESS_KEY_ID
      - name: S3_FILESTORE_AWS_SECRET_ACCESS_KEY
  templates:
    - name: cco-update-instance
      inputs:
        parameters:
          - name: INSTANCE_NAME
          - name: S3_FILESTORE_AWS_BUCKET_NAME
          - name: S3_FILESTORE_AWS_ACCESS_KEY_ID
          - name: S3_FILESTORE_AWS_SECRET_ACCESS_KEY
      volumes:
        - name: service-account-key
          secret:
            secretName: cco-service-account-key
        - name: cco-dir
          emptyDir: {}
        - name: datacity-k8s
          emptyDir: {}
      initContainers:
        - name: cco-init
          image: datacity/ckan-cloud-operator
          imagePullPolicy: Always
          volumeMounts:
            - name: service-account-key
              mountPath: /mnt/service-account-key
            - name: cco-dir
              mountPath: /mnt/cco_dir
            - name: datacity-k8s
              mountPath: /mnt/datacity_k8s
          args:
            - -c
            - |
              cp /mnt/service-account-key/service_account_key.json /mnt/cco_dir &&\
              cd /mnt/datacity_k8s &&\
              curl -sLO https://github.com/hasadna/datacity-k8s/archive/refs/heads/master.zip &&\
              unzip master.zip &&\
              mv datacity-k8s-master/* ./
      container:
        image: datacity/ckan-cloud-operator
        imagePullPolicy: Always
        volumeMounts:
          - name: cco-dir
            mountPath: /root
          - name: datacity-k8s
            mountPath: /datacity-k8s
        args:
          - -c
          - |
            set -e
            cd /datacity-k8s
            gcloud auth activate-service-account --key-file=/root/service_account_key.json
            gcloud config set project datacity-k8s
            gcloud container clusters get-credentials datacity --zone europe-west1-d
            helm init -c
            INSTANCE_NAME="{{ "{{inputs.parameters.INSTANCE_NAME}}" }}"
            S3_FILESTORE_AWS_BUCKET_NAME="{{ "{{inputs.parameters.S3_FILESTORE_AWS_BUCKET_NAME}}" }}"
            S3_FILESTORE_AWS_ACCESS_KEY_ID="{{ "{{inputs.parameters.S3_FILESTORE_AWS_ACCESS_KEY_ID}}" }}"
            S3_FILESTORE_AWS_SECRET_ACCESS_KEY="{{ "{{inputs.parameters.S3_FILESTORE_AWS_SECRET_ACCESS_KEY}}" }}"
            if ! [ -e "instances/${INSTANCE_NAME}/values.yaml" ]; then
              echo missing instance values
              exit 1
            fi
            if ( [ "${S3_FILESTORE_AWS_ACCESS_KEY_ID}" == "" ] || [ "${S3_FILESTORE_AWS_SECRET_ACCESS_KEY}" == "" ] || [ "${S3_FILESTORE_AWS_BUCKET_NAME}" == "" ] ); then
              echo missing S3 values
              exit 1
            fi
            if ! kubectl -n ckan-cloud create secret generic ckan-instance-${INSTANCE_NAME} \
                  --from-literal S3_FILESTORE_AWS_HOST_NAME=https://storage.googleapis.com \
                  --from-literal S3_FILESTORE_AWS_ACCESS_KEY_ID=${S3_FILESTORE_AWS_ACCESS_KEY_ID} \
                  --from-literal S3_FILESTORE_AWS_SECRET_ACCESS_KEY=${S3_FILESTORE_AWS_SECRET_ACCESS_KEY} \
                  --from-literal S3_FILESTORE_AWS_BUCKET_NAME=${S3_FILESTORE_AWS_BUCKET_NAME} \
                  --from-literal S3_FILESTORE_AWS_REGION_NAME=europe-west1; then
                true
            fi
            ckan-cloud-operator ckan instance create helm \
              --instance-name ${INSTANCE_NAME} \
              /datacity-k8s/instances/${INSTANCE_NAME}/values.yaml
